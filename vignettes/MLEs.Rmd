---
title: "MLE in R"
author: "Alexander Forrence"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

First, we'll load some of the necessary packages:

```{r pkgs, message=FALSE,warning=FALSE}
library(lme4)
library(bbmle)
library(optimx)
library(psyphy)
library(lattice)
library(ggplot2)
library(dplyr)

```
For example, to read in the csv containing the data for the free RT...

```{r}
free_rt <- read.csv(system.file("extdata", "bigrt.csv", package = 'multimles'),
                    header = FALSE,
                    col.names = c('id', 'RT', 'reachDir', 'hit'))
```

and for the forced RT,

```{r}
forced_rt <- read.csv(system.file("extdata", "bigtr.csv", package = 'multimles'), 
                      header = FALSE,
                      col.names = c('id', 'RT', 'reachDir', 'hit'))
```

To clean up the data a bit, try things like

```{r, eval = FALSE}
    free_rt <- free_rt[complete.cases(free_rt),]
    free_rt <- free_rt[!(free_rt$RT > 0.5),]
    free_rt <- free_rt[!(free_rt$RT < 0),]
    # Should have 1860 obs. left over (check with str())
```

Or (in `dplyr` syntax):
```{r}
free_rt <- free_rt %>% filter(!is.nan(reachDir), RT < 0.5, RT > 0)
forced_rt <- forced_rt %>% filter(!is.nan(reachDir), RT < 0.5, RT > 0)
```

Alternatives are left as an exercise to the reader.

## MLE
There were eight targets in this experiment. The objective function in `MATLAB` is specified as:

> LL = @(params) -sum(hit.*log((1/8+asymptErr*normcdf(RT,params(1),params(2))*7/8)) + (1-hit).*log(1-(1/8+asymptErr*normcdf(RT,params(1),params(2))*7/8)));

Where `asymptErr` was the upper asymptote to the probit curve (starting value of 0.9), `params(1)` was the mean (start 0.3), and `params(2)` was the sd (start 0.1).

A way to do it in R is with the `bbmle` package, a wrapper around the `mle`? function plus a number of very useful helper functions.
# Note: LL doesn't actually match Adrian's yet
```{r}
llsig <- function(mu, sigma, asymptErr, rt, hit, Ntargs){
    p1 <- log(1/Ntargs + asymptErr * pnorm(rt, mu, sigma)*(1 - 1/Ntargs))
    p2 <- log(1 - (1/Ntargs + asymptErr * pnorm(rt, mu, sigma) * (1 - 1/Ntargs)))
    -sum(hit %*% p1 + (1 - hit) %*% p2)
}
    
start_vals <- list(mu = 0.3, sigma = 0.1, asymptErr = 0.9)
subdat <- dplyr::filter(forced_rt, id == 5)
mod1 <- mle2(llsig,
            start = start_vals, 
            method = "BFGS", 
            optimizer = "optim",
            data = list(rt = subdat$RT, hit = subdat$hit),
            fixed = list(Ntargs = 8))
```
    
It takes some work to get answers out of `mle2`, and the optimizers in R aren't as robust as MATLAB's (at least I've heard).

Interpretation isn't as direct, but this sort of thing can be fit with `lme4`.

```{r}
mlme <- glmer(hit ~ RT + (1|id), 
              data = forced_rt, 
              family = binomial(link = mafc.probit(8)))
    mlme2 <- update(mlme, .~. + (0 + RT|id)) # enforcing correlation doesn't work
    anova(mlme, mlme2)
    lmeprof2 <- profile(mlme2)
    
    xyplot(lmeprof2)
```
